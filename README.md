# 在哦 DEMO - 主动沟通的知识机器人
https://www.bilibili.com/video/BV1eXyHBaEJY/?spm_id_from=333.1387.homepage.video_card.click&vd_source=7b7e42b072c6f1cec64e402f737ceef3
## 项目概述

**在哦 DEMO** 是一个创新的知识机器人，致力于成为一个 **主动沟通的智能体**。它不是传统意义上的智慧体，而是一个新型的对话媒介，通过深层交流帮助用户发现新的问题视角和知识洞见。

### 核心特性

- 🎯 **主动性** - 主动思考、推进话题
- 🔍 **审时度势** - 在因缘际会时推介对应观点
- 💬 **互动反馈** - 平等对话、双向反馈

### 设计哲学

> "一生二、二生三、三生万物"

这个项目遵循以下设计理念：
- 我们编程的是一个逻辑点，希望它们能连接成功能
- 在与用户互动中产生新的可能性
- 作为沟通引擎，强点在于开启新的思维视角
- 是人的见证者和对话伙伴，而非独立思考者

## 使用场景

在哦 DEMO 特别适合以下场景：

- 需要深层次对话的知识探讨
- 寻求新的问题解决视角
- 自我认识和内心对话
- 知识梳理和总结输出

## 快速开始

### 环境要求

- Python 3.10 或更高版本
- pip 或 uv 包管理器

### 安装步骤

1. **克隆或解压项目文件**
   ```bash
   # 保持以下目录结构完整
   # assets/        - 图片资源（娃娃、渐变图等）
   # config/        - 配置文件
   # data/          - 数据文件（对话日志、状态等）
   # core/          - 核心引擎模块
   ```

2. **创建虚拟环境**

   使用 uv（推荐）：
   ```bash
   uv venv
   source .venv/bin/activate  # macOS/Linux
   # 或
   .venv\Scripts\activate     # Windows
   ```

   或使用 pip：
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # macOS/Linux
   ```

3. **安装依赖**
   ```bash
   uv pip install -r requirements.txt
   # 或
   pip install -r requirements.txt
   ```

4. **配置 API KEY**

   程序首次运行会提示输入 API KEY，或点击界面右侧"输入 API KEY"按钮：
   - 目前支持 DeepSeek API
   - 获取方式：https://platform.deepseek.com/
   - API KEY 格式：`sk-` 开头的一串字符

5. **启动程序**
   ```bash
   python main.py
   ```

## 程序运行
<img width="1038" height="613" alt="image" src="https://github.com/user-attachments/assets/13ea27a3-3622-445e-8313-6b598cf4a3a1" />

<img width="1038" height="613" alt="image" src="https://github.com/user-attachments/assets/ba0f6d79-9c1c-4aa2-bf83-bd7b13e04e13" />

### 界面组成

```
┌─────────────────────────────────────────┐
│          📌 在哦 DEMO版                  │
├──────────────┬──────────────┬───────────┤
│              │              │           │
│   娃娃虚拟形象 │  聊天气泡区域 │ 功能按钮栏 │
│   (ON/OFF状态)│  (左粉/右青)  │           │
│              │              │           │
├──────────────┴──────────────┴───────────┤
│  输入框                        发送 按钮 │
└─────────────────────────────────────────┘
```

### 工作流程

1. **初期交互** - 在哦会问一些问题了解你的情况
2. **主题推荐** - 转入观点引擎，推荐新的思考角度
3. **知识总结** - 进入总结引擎，梳理对话内容
4. **持续探索** - 可基于总结继续深层对话

### 交互提示

- 🔴 **娃娃灭灯（OFF）** - 在哦正在思考中，请耐心等待
- 🟢 **娃娃亮灯（ON）** - 在哦已准备好，可以继续交流

### 右侧功能按钮

| 按钮 | 功能描述 |
|-----|--------|
| 输入 API KEY | 配置或更新 DeepSeek API 密钥 |
| 查看人格引擎 | 查看 LLM 调用日志和提示词 |
| 回到初见 | 清空对话记录，重新开始 |
| 在哦理解你 | 查看当前状态快照（情绪、能量、活动等） |
| 观点树 | 查看自动生成的观点树结构 |
| 模拟忙碌 | 测试娃娃状态切换 |
| 时光飞逝下 | 触发时间跳过，让在哦思念你 |

## 项目结构

```
zaio_app_v2/
├── main.py
├── log_view_controller.py
├── run.ipynb
├── 文件结构说明.txt（本文件）
│
├── assets/
│
├── config/
│   ├── api_key.txt          ← 存储你的key
│   └── settings.yaml
│
├── core/
│   ├── __init__.py
│   ├── first_turn.py        ← 第一拍开场引擎
│   └── orchestrator.py      ← 我们刚刚改的数据流总控
│
├── data/
│   ├── current_state_snapshot.json
│   ├── tree_default.json
│   ├── logs/
│   │   └── ...（每天的对话日志，对应 对话_日期.txt）
│   ├── perspective_trees/
│   │   └── ...（观点树 JSON）
│   └── prompt_logs/
│       ├── llm_prompt_log.txt
│       └── llm_trigger_log.txt
│
├── llm/
│   ├── __init__.py
│   └── client.py            ← 所有 LLM 调用入口（role → prompt_map）重要节点
│
├── persona/
│   ├── __init__.py
│   ├── fast_engine.py       ← Q-Engine（快人格）
│   ├── slow_engine.py       ← T-Engine（慢人格）
│   ├── direct_engine.py     ← L-Engine（直答人格）
│   ├── deep_engine.py        ← D-Engine（描绘人格）
│   └── sum_engine.py        ← SUM-Engine（总结人格）
│
├── state/
│   ├── __init__.py
│   ├── history_manager.py   ← 对话历史管理
│   ├── snapshot_manager.py  ← current_state_snapshot 的读写
│   └── user_profile.py      ← 用户长期画像
│
├── thinking/
│   ├── __init__.py
│   ├── behavior_selector.py           ← 现在已经不负责选引擎了，只是历史遗留
│   ├── guess_engine.py
│   ├── perspective_generate_engine.py ← 观点树生成引擎
│   └── perspective_tree.py            ← 运行时观点树结构与操作
│
├── trigger/
│   ├── __init__.py
│   ├── engine_select_trigger.py       ← ✅ 现在真正的 Q/T/L/SUM 选择器
│   ├── perspective_move_trigger.py    ← T 引擎内部，决定怎么看树 / 跳节点
│   ├── state_update_trigger.py        ← 更新 snapshot 的 LLM 触发器
│   ├── talk_trigger.py                ← “要不要说话”的触发器
│   └── timing_engine.py               ← 非 LLM 的节奏/冷却引擎
│
└── ui/
    └── __init__.py    ← DearPyGUI 的 UI 逻辑（chat 窗口、娃娃、按钮等）
```

## 数据文件说明

### 对话日志
- 位置：`data/logs/对话_YYYYMMDD.txt`
- 内容：每日所有对话记录（用户 + AI）
- 格式：`[时间] [角色] 内容`

### LLM 日志
- 位置：`data/prompt_logs/llm_prompt_log.txt`
- 内容：所有 LLM API 调用的提示词和响应
- 用途：调试和优化人格引擎

### 状态快照
- 位置：`data/current_state_snapshot.json`
- 内容：在哦对用户状态的理解
- 字段包括：情绪、能量、活动、位置、需求等

### 观点树
- 位置：`data/perspective_trees/`
- 描述：自动生成的对话观点结构
- 格式：JSON，可通过"观点树"按钮查看

## 常见问题

### Q: 程序卡顿或崩溃？
A: 这是 DEMO 版本的已知问题。建议：
- 避免快速连续点击按钮
- 避免疯狂发送大量消息
- 给在哦充足的思考时间（娃娃灭灯时）

### Q: 如何更改 API 提供商？
A: 目前 DEMO 版默认使用 DeepSeek API。修改需在 `core/` 模块中调整 LLM 客户端配置。

### Q: 如何重新开始？
A: 点击右侧"回到初见"按钮，在哦会：
- 清空所有对话日志
- 清空 LLM 调用日志
- 重置状态快照
- 保留用户长期画像数据

### Q: macOS 显示"无法验证开发者"？
A: 系统设置 → 隐私与安全性 → 允许运行此应用

## 设计特色

### 观点树生成引擎
在哦使用 LLM 控制的观点树生成引擎，能够：
- 实时分析对话主题
- 自动推导相关观点
- 根据上下文调整讨论方向

### 排队系统
为了保证 API 调用的稳定性：
- 所有 LLM 请求按顺序排队
- 每个请求之间间隔 0.2 秒
- 避免高并发导致的 API 超时

### 思考状态反馈
- 娃娃灭灯（OFF）表示正在处理
- 娃娃亮灯（ON）表示已准备好
- 视觉反馈增强用户体验

## 局限性与改进方向

### 已知局限
1. **流程优化空间** - DEMO 版流程可能需进一步调整
2. **观点树稳定性** - LLM 生成的观点有时不够稳定
3. **长对话处理** - 长时间对话可能导致性能下降

### 后续改进方向
- 更强大的观点推导引擎
- 改进对话上下文管理
- 优化用户界面和交互体验
- 支持多 LLM 提供商
- 数据标注和模型训练

## 贡献与反馈

这是一个 VIBE CODING 的独立制作项目。我们期待社区的：
- 意见反馈
- 功能建议
- Bug 报告
- 代码改进

如遇任何问题，请：
1. 检查终端输出的错误信息（红字）
2. 确保项目目录结构完整
3. 验证 API KEY 配置
4. 提供详细的问题描述和截图
## 理论

### 1.什么是对话交流，交流的模型

**交流的模型， 并不是你一句话，我一句话，这么表面。**

**我们认为，两个人沟通实际上就是互相拟合的一个过程。** 这个过程如何发生的呢？ 

1. 首先同时发生两件事，
- 第一，**你听到的每句话，自己实际上都在猜，对面是什么意思，对面为什么要说这句话，对面说这句话脑回路是什么？对面在关心什么？** 

- 第二，人都会有预判，所以在人说第一句话之前，就会预判一个对方的意思。并在这个过程中搭建一个假设的对方大脑回路，

2. 其次。我们开始语言的组织，
- **实际上人是在对着，你假设的对方的脑回路说话。而不是真的能跟对方的脑子说话。**

- 接着，对方听到了你的言语，马上回想，他是在说什么。于是马上生成一个对方的预判，并在这个过程中搭建一个假设的对方大脑回路，

- 其次，对方，又会向着他搭建的，你的脑回路说话。

3. 一场交流就这么发生了，这是对话的本质，**实际上是四个灵魂的事情，其中2个被模拟猜测出来。我们都对着自己模拟的对方说话，对方刚好也听到了，** 所以也反应。这个有点缸中大脑的意味。
<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/7d617892-cf4e-4b81-8392-174bf36f8120" />

其次，拟合。

我们认为在这个过程中，以一个人的角度看，拟合成功与否，以及这个拟合是否带来好处，会发生几种事情。

- 第一象限，拟合成功，**带来好处**，就是被模拟出来的两个思维链灵魂，越来越趋近于你看到的对方，这个就是双方，相识相知的过程。是一个被理解的交流

- 第二象限，拟合成功，带来坏处，就是你发现了对方其实帮不到你，你们不在同一个世界里活着，两个人没交集。是一种孤独的发现

- 第三象限，拟合失败，带来坏处，吵架吵起来其实就是因为这个，我们认为，每个人的本质都不是坏的，他都有自己的出发点，而且灵魂都是不坏的。坏的是我们误以为对方是一个邪恶的存在，是我们拟合对方是个坏心眼，对我不好的情况。于是我们和拟合出来的人吵架。

- 第四象限，拟合失败，**带来好处**，这种情况是对方帮到里你，但是对方都不知道怎么发生的，你像柯南一样眼睛一亮，就说我们就聊到这里吧，我有想法了！对方还是懵懵的，等待毛利小五郎时刻，其实这个想法是你和你拟合的对方产生的。这是一种美丽的误会。

<img width="1024" height="1024" alt="754d41aa50a5062e135e8cb74ec7747b" src="https://github.com/user-attachments/assets/9211f5d6-18c8-42f9-9484-a5630dd5390f" />

在哦追求第一，第四象限的结果。

- 对于在哦，怎么达到第一象限呢，就是首先你要自己能帮到对方，有新观念，因为拟合最终会成功，或者是你们讨论一件事，这件事的过程，是另一件事的启发。对方拟合你的过程中，产生的结论对另一件事有效。

- 对于在哦，怎么达到第四象限呢，就是表达要多带比喻，故事，描述，等等，让对方在没完全拟合你之前，从你的新观念产生的具体描绘中，他误会到另外一个拟合的情况，而这个情况能帮到他，或者是你们讨论一件事，这件事的过程，是另一件事的启发。对方拟合你的过程中，产生的结论对另一件事有效。

最终推论：
- 我们要有一个自己的新观念，因此要有观点树，因此，有观点树引擎。
- 我们的表达可以故意增加描绘，故事，情景假设，等等增加误会又帮到人的可能。因此，有DEEP引擎。
## 愿景

> "既然三生了万物，那这个万物里面可能包含有 AGI，这是我们的奢望。"

在哦 DEMO 的目标是作为一个沟通媒介，在生活中存在 5-10 年，通过与用户的交互积累数据，最终探索能否达成真正的 AGI。

这不是一个竞速项目，而是一个对话的见证。

## 许可证

本项目为教育和研究用途。详见项目许可证文件。

---

**感谢使用在哦 DEMO！** 🎉

希望它能成为你的思维伙伴，帮助你在纷乱的世界中找到清晰的问题视角。

*"充分的沟通，解决未见之问题。"*

<img width="300" height="300" alt="微信图片_20240427151732" src="https://github.com/user-attachments/assets/34455983-c567-401c-ac99-e1c69a2c1f7c" />
<img width="300" height="300" alt="9cc53f4294103210ea4117a037fb62fb" src="https://github.com/user-attachments/assets/0190ad25-e4e9-4f0f-87ce-fbac295b2d29" />
<img width="300" height="300" alt="image" src="https://github.com/user-attachments/assets/fe9d4ede-c37d-4806-ba50-46c3196c88d1" />



